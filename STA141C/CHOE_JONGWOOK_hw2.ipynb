{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STA 141C - Big Data & High Performance Statistical Computing Spring 2022\n",
    "\n",
    "#### Homework # 2\n",
    "\n",
    "##### JONGWOOk CHOE\n",
    "\n",
    "##### May 6, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as sl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.sparse as sparse\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in the ‘longley.dat’ with the response (number of people employed) in the first column and six explanatory variables in the other columns (GNP implicit price deflator, Gross National Product, number of unemployed, number of people in the armed forces, “noninstitutionalized” population % 14 years of age, year). Include an intercept in you model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data using pandas\n",
    "longley = pd.read_csv(\"longley.dat\", header=None, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of people employed</th>\n",
       "      <th>GNP implicit price deflator</th>\n",
       "      <th>Gross National Product</th>\n",
       "      <th>number of unemployed</th>\n",
       "      <th>number of people in the armed forces</th>\n",
       "      <th>noninstitutionalized population</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60323</td>\n",
       "      <td>83.0</td>\n",
       "      <td>234289</td>\n",
       "      <td>2356</td>\n",
       "      <td>1590</td>\n",
       "      <td>107608</td>\n",
       "      <td>1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61122</td>\n",
       "      <td>88.5</td>\n",
       "      <td>259426</td>\n",
       "      <td>2325</td>\n",
       "      <td>1456</td>\n",
       "      <td>108632</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60171</td>\n",
       "      <td>88.2</td>\n",
       "      <td>258054</td>\n",
       "      <td>3682</td>\n",
       "      <td>1616</td>\n",
       "      <td>109773</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61187</td>\n",
       "      <td>89.5</td>\n",
       "      <td>284599</td>\n",
       "      <td>3351</td>\n",
       "      <td>1650</td>\n",
       "      <td>110929</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63221</td>\n",
       "      <td>96.2</td>\n",
       "      <td>328975</td>\n",
       "      <td>2099</td>\n",
       "      <td>3099</td>\n",
       "      <td>112075</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number of people employed  GNP implicit price deflator  \\\n",
       "0                      60323                         83.0   \n",
       "1                      61122                         88.5   \n",
       "2                      60171                         88.2   \n",
       "3                      61187                         89.5   \n",
       "4                      63221                         96.2   \n",
       "\n",
       "   Gross National Product  number of unemployed  \\\n",
       "0                  234289                  2356   \n",
       "1                  259426                  2325   \n",
       "2                  258054                  3682   \n",
       "3                  284599                  3351   \n",
       "4                  328975                  2099   \n",
       "\n",
       "   number of people in the armed forces  noninstitutionalized population  year  \n",
       "0                                  1590                           107608  1947  \n",
       "1                                  1456                           108632  1948  \n",
       "2                                  1616                           109773  1949  \n",
       "3                                  1650                           110929  1950  \n",
       "4                                  3099                           112075  1951  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the columns \n",
    "longley.rename(columns={0:\"number of people employed\", 1:\"GNP implicit price deflator\", 2: \"Gross National Product\", 3:\"number of unemployed\",\n",
    "4: \"number of people in the armed forces\", 5: \"noninstitutionalized population\", 6: \"year\"}, inplace=True)\n",
    "\n",
    "longley.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.50618723e+01 -3.58191793e-02 -2.02022980e+00 -1.03322687e+00\n",
      "  -5.11041057e-02  1.82915146e+03]]\n",
      "[-3482258.63459582]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression module\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Y\n",
    "Y = longley.iloc[:,0:1]\n",
    "\n",
    "# X\n",
    "X = longley.iloc[:,1:]\n",
    "\n",
    "# fit data\n",
    "model = lm.fit(X, Y)\n",
    "\n",
    "\n",
    "print(model.coef_)\n",
    "print(model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Assuming linear model $y \\sim N(X\\beta,\\sigma^2I),$ compute \n",
    "\n",
    "1) Regression coefficients $\\hat{\\beta} = (X^′X)^{−1}X^′y,$ \n",
    "2) Standard errors of $\\hat{\\beta} = \\sigma^2\\text{diag}((X^′X)^{−1}),$ and \n",
    "3) Variance estimate $\\hat{\\sigma}^2 = (Y -X^′\\hat{\\beta})′(Y -X^′\\hat{\\beta})$ \n",
    "\n",
    "using following methods: GE/LU decomposition, Cholesky decomposition, and QR decomposition, and compare the computation speed for each method. Please compute them directly using numerical linear algebra functions; you can use the “black-box” function (e.g., lm() in R or sklearn.linear model.LinearRegression in python) only to check your results. (Hint: chol2inv() function in R computes the inverse of a matrix from its Cholesky factor. In python, you may try cho solve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GE/LU  decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     1.      83.  234289.    2356.    1590.  107608.    1947. ]\n",
      " [     1.      88.5 259426.    2325.    1456.  108632.    1948. ]\n",
      " [     1.      88.2 258054.    3682.    1616.  109773.    1949. ]\n",
      " [     1.      89.5 284599.    3351.    1650.  110929.    1950. ]\n",
      " [     1.      96.2 328975.    2099.    3099.  112075.    1951. ]\n",
      " [     1.      98.1 346999.    1932.    3594.  113270.    1952. ]\n",
      " [     1.      99.  365385.    1870.    3547.  115094.    1953. ]\n",
      " [     1.     100.  363112.    3578.    3350.  116219.    1954. ]\n",
      " [     1.     101.2 397469.    2904.    3048.  117388.    1955. ]\n",
      " [     1.     104.6 419180.    2822.    2857.  118734.    1956. ]\n",
      " [     1.     108.4 442769.    2936.    2798.  120445.    1957. ]\n",
      " [     1.     110.8 444546.    4681.    2637.  121950.    1958. ]\n",
      " [     1.     112.6 482704.    3813.    2552.  123366.    1959. ]\n",
      " [     1.     114.2 502601.    3931.    2514.  125368.    1960. ]\n",
      " [     1.     115.7 518173.    4806.    2572.  127852.    1961. ]\n",
      " [     1.     116.9 554894.    4007.    2827.  130081.    1962. ]]\n"
     ]
    }
   ],
   "source": [
    "# make array of A and b from the data\n",
    "A = longley.iloc[:,1:]\n",
    "b = longley.iloc[:,0:1]\n",
    "\n",
    "A = np.array(A)\n",
    "\n",
    "# add column of one for intercept\n",
    "ncol = np.array(np.repeat(1, len(A)))\n",
    "ncol = ncol.reshape(-1,1)\n",
    "# ncol.shape\n",
    "\n",
    "An = np.append(A, ncol, axis=1)\n",
    "\n",
    "An = An[:, [6,0,1,2,3,4,5]]\n",
    "\n",
    "\n",
    "\n",
    "print(np.array_str(An, precision=5, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward substitution\n",
    "def forward_substitution(L, b):\n",
    "    \n",
    "    #Get number of rows\n",
    "    n = L.shape[0]\n",
    "    \n",
    "    #Allocating space for the solution vector\n",
    "    y = np.zeros_like(b, dtype=np.double);\n",
    "    \n",
    "    #Here we perform the forward-substitution.  \n",
    "    #Initializing  with the first row.\n",
    "    y[0] = b[0] / L[0, 0]\n",
    "    \n",
    "    #Looping over rows in reverse (from the bottom  up),\n",
    "    #starting with the second to last row, because  the \n",
    "    #last row solve was completed in the last step.\n",
    "    for i in range(1, n):\n",
    "        y[i] = (b[i] - np.dot(L[i,:i], y[:i])) / L[i,i]\n",
    "        \n",
    "    return y\n",
    "\n",
    "\n",
    "# backward substituion\n",
    "def back_substitution(U, y):\n",
    "    \n",
    "    #Number of rows\n",
    "    n = U.shape[0]\n",
    "    \n",
    "    #Allocating space for the solution vector\n",
    "    x = np.zeros_like(y, dtype=np.double);\n",
    "\n",
    "    #Here we perform the back-substitution.  \n",
    "    #Initializing with the last row.\n",
    "    x[-1] = y[-1] / U[-1, -1]\n",
    "    \n",
    "    #Looping over rows in reverse (from the bottom up), \n",
    "    #starting with the second to last row, because the \n",
    "    #last row solve was completed in the last step.\n",
    "    for i in range(n-2, -1, -1):\n",
    "        x[i] = (y[i] - np.dot(U[i,i:], x[i:])) / U[i,i]\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X' * X\n",
    "Asq = np.dot(np.transpose(An),An)\n",
    "\n",
    "# Compute LU decomposition\n",
    "P, L, U = sl.lu(Asq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X' * b\n",
    "B = np.dot(An.T, b)\n",
    "\n",
    "# P' * yhat (pivoting)\n",
    "Y = np.dot(P.T, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression coefficient betahat is : \n",
      "[[ 1.50618727e+01]\n",
      " [-3.58191799e-02]\n",
      " [-2.02022981e+00]\n",
      " [-1.03322687e+00]\n",
      " [-5.11041037e-02]\n",
      " [ 1.82915147e+03]]\n"
     ]
    }
   ],
   "source": [
    "# Compute forward subsitution for L(Ub) = P'* yhat\n",
    "Ub = forward_substitution(L, Y)\n",
    "\n",
    "# find a coefficient by backward substitution\n",
    "betahat = back_substitution(U, Ub)\n",
    "\n",
    "print(\"The regression coefficient betahat is : \")\n",
    "print(betahat[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sterror(data):\n",
    "    return np.std(data, ddof=1) / np.sqrt(np.size(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error is 304.4723404317628\n",
      "\n",
      "\n",
      "Variance is \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.24431389e+12, -8.29486519e+07,  1.30284638e+05,\n",
       "         1.94619875e+06,  5.61468345e+05, -4.42559942e+05,\n",
       "        -2.17042820e+09],\n",
       "       [-8.29486520e+07,  3.85998285e+04, -9.88676650e+00,\n",
       "        -1.23216715e+02, -3.39755116e+01,  6.77412799e+01,\n",
       "         3.85696793e+04],\n",
       "       [ 1.30284638e+05, -9.88676649e+00,  6.00445701e-03,\n",
       "         8.28002681e-02,  1.80020602e-02, -3.37712290e-02,\n",
       "        -6.54658675e+01],\n",
       "       [ 1.94619875e+06, -1.23216715e+02,  8.28002681e-02,\n",
       "         1.27693283e+00,  3.46535916e-01, -4.48185498e-01,\n",
       "        -9.81388938e+02],\n",
       "       [ 5.61468345e+05, -3.39755116e+01,  1.80020602e-02,\n",
       "         3.46535916e-01,  2.45785876e-01, -4.89893272e-02,\n",
       "        -2.87023691e+02],\n",
       "       [-4.42559942e+05,  6.77412799e+01, -3.37712290e-02,\n",
       "        -4.48185498e-01, -4.89893272e-02,  2.73599607e-01,\n",
       "         2.13966085e+02],\n",
       "       [-2.17042820e+09,  3.85696792e+04, -6.54658675e+01,\n",
       "        -9.81388937e+02, -2.87023691e+02,  2.13966085e+02,\n",
       "         1.11058824e+06]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LUste = sterror(betahat)\n",
    "\n",
    "LUvar = np.dot(LUste, np.linalg.inv(Asq))\n",
    "print(f\"The standard error is {sterror(betahat[1:])}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Variance is \")\n",
    "LUvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cholesky decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.48225863e+06],\n",
       "       [ 1.50618723e+01],\n",
       "       [-3.58191793e-02],\n",
       "       [-2.02022980e+00],\n",
       "       [-1.03322687e+00],\n",
       "       [-5.11041056e-02],\n",
       "       [ 1.82915146e+03]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cholesky factor first\n",
    "c, low = cho_factor(Asq)\n",
    "\n",
    "# Then compute betahat by using cho_solve function\n",
    "xhat = cho_solve((c, low), B)\n",
    "xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression coefficient betahat is : \n",
      "[[ 1.50618723e+01]\n",
      " [-3.58191793e-02]\n",
      " [-2.02022980e+00]\n",
      " [-1.03322687e+00]\n",
      " [-5.11041056e-02]\n",
      " [ 1.82915146e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The regression coefficient betahat is : \")\n",
    "print(xhat[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error is 304.4723388995521\n",
      "\n",
      "\n",
      "Variance is \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.24431387e+12, -8.29486514e+07,  1.30284637e+05,\n",
       "         1.94619874e+06,  5.61468342e+05, -4.42559940e+05,\n",
       "        -2.17042819e+09],\n",
       "       [-8.29486516e+07,  3.85998283e+04, -9.88676645e+00,\n",
       "        -1.23216714e+02, -3.39755115e+01,  6.77412796e+01,\n",
       "         3.85696790e+04],\n",
       "       [ 1.30284638e+05, -9.88676644e+00,  6.00445697e-03,\n",
       "         8.28002677e-02,  1.80020601e-02, -3.37712288e-02,\n",
       "        -6.54658672e+01],\n",
       "       [ 1.94619874e+06, -1.23216714e+02,  8.28002677e-02,\n",
       "         1.27693282e+00,  3.46535914e-01, -4.48185496e-01,\n",
       "        -9.81388933e+02],\n",
       "       [ 5.61468342e+05, -3.39755115e+01,  1.80020601e-02,\n",
       "         3.46535914e-01,  2.45785874e-01, -4.89893269e-02,\n",
       "        -2.87023690e+02],\n",
       "       [-4.42559940e+05,  6.77412796e+01, -3.37712288e-02,\n",
       "        -4.48185496e-01, -4.89893270e-02,  2.73599606e-01,\n",
       "         2.13966084e+02],\n",
       "       [-2.17042819e+09,  3.85696790e+04, -6.54658672e+01,\n",
       "        -9.81388932e+02, -2.87023690e+02,  2.13966084e+02,\n",
       "         1.11058823e+06]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chste = sterror(xhat)\n",
    "\n",
    "chvar = np.dot(chste, np.linalg.inv(Asq))\n",
    "\n",
    "\n",
    "print(f\"The standard error is {sterror(xhat[1:])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Variance is \")\n",
    "chvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### QR decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, r = sl.qr(An)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.dot(q.T, np.array(b))\n",
    "xhat_qr = np.dot(np.linalg.pinv(r), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regression coefficient betahat is : \n",
      "[[ 1.50618723e+01]\n",
      " [-3.58191793e-02]\n",
      " [-2.02022980e+00]\n",
      " [-1.03322687e+00]\n",
      " [-5.11041057e-02]\n",
      " [ 1.82915146e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The regression coefficient betahat is : \")\n",
    "print(xhat_qr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard error is 304.4723388907928\n",
      "\n",
      "\n",
      "Variance is \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.24431387e+12, -8.29486514e+07,  1.30284637e+05,\n",
       "         1.94619874e+06,  5.61468342e+05, -4.42559940e+05,\n",
       "        -2.17042819e+09],\n",
       "       [-8.29486516e+07,  3.85998283e+04, -9.88676645e+00,\n",
       "        -1.23216714e+02, -3.39755115e+01,  6.77412796e+01,\n",
       "         3.85696790e+04],\n",
       "       [ 1.30284638e+05, -9.88676644e+00,  6.00445697e-03,\n",
       "         8.28002677e-02,  1.80020601e-02, -3.37712288e-02,\n",
       "        -6.54658672e+01],\n",
       "       [ 1.94619874e+06, -1.23216714e+02,  8.28002677e-02,\n",
       "         1.27693282e+00,  3.46535914e-01, -4.48185496e-01,\n",
       "        -9.81388933e+02],\n",
       "       [ 5.61468342e+05, -3.39755115e+01,  1.80020601e-02,\n",
       "         3.46535914e-01,  2.45785874e-01, -4.89893269e-02,\n",
       "        -2.87023690e+02],\n",
       "       [-4.42559940e+05,  6.77412796e+01, -3.37712288e-02,\n",
       "        -4.48185496e-01, -4.89893270e-02,  2.73599606e-01,\n",
       "         2.13966084e+02],\n",
       "       [-2.17042819e+09,  3.85696790e+04, -6.54658672e+01,\n",
       "        -9.81388932e+02, -2.87023690e+02,  2.13966084e+02,\n",
       "         1.11058823e+06]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrste = sterror(xhat)\n",
    "\n",
    "qrvar = np.dot(qrste, np.linalg.inv(Asq))\n",
    "print(f\"The standard error is {sterror(xhat_qr[1:])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Variance is \")\n",
    "\n",
    "qrvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. One popular regularization method is the ridge regression, which estimates regression coefficients by minimizing a penalized least squares criterion\n",
    "$$\\frac{1}{2}||y-X\\beta||^2_2+\\frac{\\lambda}{2}||\\beta||^2_2$$\n",
    "show that the ridge solution is given by\n",
    "$$\\hat{\\beta}_{\\lambda}=(X'X +\\lambda I_p)^{-1}X'y.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the ridge solution is given by \n",
    "\n",
    "$$\\hat{\\beta}_\\lambda = (X'X + \\lambda I)^{-1}X^TY$$\n",
    "\n",
    "we need to solve that\n",
    "\n",
    "$$(Y - \\beta'X)'(Y - \\beta'X) + \\lambda\\beta'\\beta$$ \n",
    "\n",
    "$$ => Y^TY - 2\\beta'X'Y + \\beta^tX'X\\beta + \\lambda\\beta'\\beta  $$\n",
    "\n",
    "First, we differentiate the above equation.\n",
    "\n",
    "Then, we get\n",
    "\n",
    "\n",
    "$$-2X'Y + 2X'X\\beta + 2\\lambda\\beta $$\n",
    "\n",
    "Now, we have to solve it for 0 and then for $\\hat{\\beta}_\\lambda$ \n",
    "\n",
    "$$-2X'Y + 2X'X\\beta + 2\\lambda\\beta = 0 $$\n",
    "\n",
    "$$= -X'Y + X'X\\beta + \\lambda\\beta = 0 $$\n",
    "\n",
    "$$= X'X\\beta + \\lambda\\beta = X'Y  $$\n",
    "\n",
    "$$= (X'X + \\lambda I)\\beta = X'Y $$\n",
    "\n",
    "Hence, we have proved that\n",
    "\n",
    "$$ \\hat{\\beta}_\\lambda = (X'X + \\lambda I)^{-1}X'Y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute the ridge regression estimates $\\hat{\\beta}_{lambda}$ at a set of different values of $\\lambda (\\text{e.g. }, 0, 1, 2, \\cdots , 100)$ by solving it as a least squares problem. Plot the $l_2$-norm of the ridge coefficients $||\\hat{\\beta}_{\\lambda}||$ as a function of $\\lambda$. You can use either QR or Cholesky method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = longley[['number of people employed']]\n",
    "x = longley.iloc[:,1:]     \n",
    "\n",
    "# create intercept \n",
    "itcpt = np.repeat(1,16).reshape(-1,1)\n",
    "\n",
    "x = np.append(x, itcpt, axis = 1)\n",
    "x = x[:,[6,0,1,2,3,4,5]]\n",
    "\n",
    "\n",
    "X = x.T.dot(x)\n",
    "Y = x.T.dot(y)\n",
    "\n",
    "# lambda from 1 to 100\n",
    "ly = np.arange(1,100,0.1) \n",
    "\n",
    "\n",
    "df = np.arange(1,8).reshape(1,-1) \n",
    "\n",
    "# compute and add penalty\n",
    "for i in ly:\n",
    "    pty = i * np.eye(7)\n",
    "    X = X + pty\n",
    "    c, low = cho_factor(X)\n",
    "    btas = cho_solve((c,low),Y).reshape(1,-1)\n",
    "    df = np.vstack((df, btas))\n",
    "\n",
    "# remove the first r.n given\n",
    "# combine to df\n",
    "df = pd.DataFrame(df[1:,:]) \n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(ly, df[0], label='b_0')\n",
    "plt.plot(ly, df[1], label='b_1')\n",
    "plt.plot(ly, df[2], label='b_2')\n",
    "plt.plot(ly, df[3], label='b_3')\n",
    "plt.plot(ly, df[4], label='b_4')\n",
    "plt.plot(ly, df[5], label='b_5')\n",
    "plt.plot(ly, df[6], label='b_6')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Beta')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Implement your code using parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (Bonus 1 point) Find out which method is the lm() function in R is using? And which algorithm is being used? Or find out which method is the linear regression function (there are multiple, but only need to choose one) in numpy/scipy is using? And which algorithm is being used?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c178aea58de6e77b93b19ccdcc6dacff0444b89d2a7888d60013d84570d1a9a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
