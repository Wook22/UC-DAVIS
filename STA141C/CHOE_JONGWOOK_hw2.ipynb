{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STA 141C - Big Data & High Performance Statistical Computing Spring 2022\n",
    "\n",
    "#### Homework # 2\n",
    "\n",
    "##### JONGWOOk CHOE\n",
    "\n",
    "##### May 6, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.sparse as sparse\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in the ‘longley.dat’ with the response (number of people employed) in the first column and six explanatory variables in the other columns (GNP implicit price deflator, Gross National Product, number of unemployed, number of people in the armed forces, “noninstitutionalized” population % 14 years of age, year). Include an intercept in you model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data using pandas\n",
    "longley = pd.read_csv(\"longley.dat\", header=None, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of people employed</th>\n",
       "      <th>GNP implicit price deflator</th>\n",
       "      <th>Gross National Product</th>\n",
       "      <th>number of unemployed</th>\n",
       "      <th>number of people in the armed forces</th>\n",
       "      <th>noninstitutionalized population</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60323</td>\n",
       "      <td>83.0</td>\n",
       "      <td>234289</td>\n",
       "      <td>2356</td>\n",
       "      <td>1590</td>\n",
       "      <td>107608</td>\n",
       "      <td>1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61122</td>\n",
       "      <td>88.5</td>\n",
       "      <td>259426</td>\n",
       "      <td>2325</td>\n",
       "      <td>1456</td>\n",
       "      <td>108632</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60171</td>\n",
       "      <td>88.2</td>\n",
       "      <td>258054</td>\n",
       "      <td>3682</td>\n",
       "      <td>1616</td>\n",
       "      <td>109773</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61187</td>\n",
       "      <td>89.5</td>\n",
       "      <td>284599</td>\n",
       "      <td>3351</td>\n",
       "      <td>1650</td>\n",
       "      <td>110929</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63221</td>\n",
       "      <td>96.2</td>\n",
       "      <td>328975</td>\n",
       "      <td>2099</td>\n",
       "      <td>3099</td>\n",
       "      <td>112075</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number of people employed  GNP implicit price deflator  \\\n",
       "0                      60323                         83.0   \n",
       "1                      61122                         88.5   \n",
       "2                      60171                         88.2   \n",
       "3                      61187                         89.5   \n",
       "4                      63221                         96.2   \n",
       "\n",
       "   Gross National Product  number of unemployed  \\\n",
       "0                  234289                  2356   \n",
       "1                  259426                  2325   \n",
       "2                  258054                  3682   \n",
       "3                  284599                  3351   \n",
       "4                  328975                  2099   \n",
       "\n",
       "   number of people in the armed forces  noninstitutionalized population  year  \n",
       "0                                  1590                           107608  1947  \n",
       "1                                  1456                           108632  1948  \n",
       "2                                  1616                           109773  1949  \n",
       "3                                  1650                           110929  1950  \n",
       "4                                  3099                           112075  1951  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the columns \n",
    "longley.rename(columns={0:\"number of people employed\", 1:\"GNP implicit price deflator\", 2: \"Gross National Product\", 3:\"number of unemployed\",\n",
    "4: \"number of people in the armed forces\", 5: \"noninstitutionalized population\", 6: \"year\"}, inplace=True)\n",
    "\n",
    "longley.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression module\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Y\n",
    "Y = longley.iloc[:,0:1]\n",
    "\n",
    "# X\n",
    "X = longley.iloc[:,1:]\n",
    "\n",
    "# fit data\n",
    "model = lm.fit(X, Y)\n",
    "\n",
    "\n",
    "print(model.coef_)\n",
    "print(model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Assuming linear model $y \\sim N(X\\beta,\\sigma^2I), \\text{compute  } 1)$ regression coefficients $\\hat{\\beta} = (X^′X)^{−1}X^′y, 2)$ standard errors of $\\hat{\\beta} = \\sigma^2\\text{diag}((X^′X)^{−1}), \\text{ and } 3)$ variance estimate $\\hat{\\sigma}^2 = (Y -X^′\\hat{\\beta})′(Y -X^′\\hat{\\beta})$ using following methods: GE/LU decomposition, Cholesky decomposition, and QR decomposition, and compare the computation speed for each method. Please compute them directly using numerical linear algebra functions; you can use the “black-box” function (e.g., lm() in R or sklearn.linear model.LinearRegression in python) only to check your results. (Hint: chol2inv() function in R computes the inverse of a matrix from its Cholesky factor. In python, you may try cho solve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. One popular regularization method is the ridge regression, which estimates regression coefficients by minimizing a penalized least squares criterion\n",
    "$$\\frac{1}{2}||y-X\\beta||^2_2+\\frac{\\lambda}{2}||\\beta||^2_2$$\n",
    "show that the ridge solution is given by\n",
    "$$\\hat{\\beta}_{\\lambda}=(X'X +\\lambda I_p)^{-1}X'y.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the ridge solution is given by \n",
    "\n",
    "$$\\hat{\\beta}_\\lambda = (X^TX + \\lambda I)^{-1}X^TY$$\n",
    "\n",
    "we need to solve that\n",
    "\n",
    "$$(Y - \\beta^TX)^T(Y - \\beta^TX) + \\lambda\\beta^T\\beta$$ \n",
    "\n",
    "$$ => Y^TY - 2\\beta^TX^TY + \\beta^tX^TX\\beta + \\lambda\\beta^T\\beta  $$\n",
    "\n",
    "First, we differentiate the above equation.\n",
    "\n",
    "Then, we get\n",
    "\n",
    "\n",
    "$$-2X^TY + 2X^TX\\beta + 2\\lambda\\beta $$\n",
    "\n",
    "Now, we have to solve it for 0 and then for $\\hat{\\beta}_\\lambda$ \n",
    "\n",
    "$$-2X^TY + 2X^TX\\beta + 2\\lambda\\beta = 0 $$\n",
    "\n",
    "$$= -X^TY + X^TX\\beta + \\lambda\\beta = 0 $$\n",
    "\n",
    "$$= X^TX\\beta + \\lambda\\beta = X^TY  $$\n",
    "\n",
    "$$= (X^TX + \\lambda I)\\beta = X^TY $$\n",
    "\n",
    "Hence, we have proved that\n",
    "\n",
    "$$ \\hat{\\beta}_\\lambda = (X^TX + \\lambda I)^{-1}X^TY$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compute the ridge regression estimates $\\hat{\\beta}_{lambda}$ at a set of different values of $\\lambda (\\text{e.g. }, 0, 1, 2, \\cdots , 100)$ by solving it as a least squares problem. Plot the $l_2$-norm of the ridge coefficients $||\\hat{\\beta}_{\\lambda}||$ as a function of $\\lambda$. You can use either QR or Cholesky method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = longley[['number of people employed']]\n",
    "x = longley.iloc[:,1:]     \n",
    "\n",
    "# create intercept \n",
    "itcpt = np.repeat(1,16).reshape(-1,1)\n",
    "\n",
    "x = np.append(x, itcpt, axis = 1)\n",
    "x = x[:,[6,0,1,2,3,4,5]]\n",
    "\n",
    "\n",
    "X = x.T.dot(x)\n",
    "Y = x.T.dot(y)\n",
    "\n",
    "# lambda from 1 to 100\n",
    "ly = np.arange(1,100,0.1) \n",
    "\n",
    "\n",
    "df = np.arange(1,8).reshape(1,-1) \n",
    "\n",
    "# compute and add penalty\n",
    "for i in ly:\n",
    "    pty = i * np.eye(7)\n",
    "    X = X + pty\n",
    "    c, low = cho_factor(X)\n",
    "    btas = cho_solve((c,low),Y).reshape(1,-1)\n",
    "    df = np.vstack((df, btas))\n",
    "\n",
    "# remove the first r.n given\n",
    "# combine to df\n",
    "df = pd.DataFrame(df[1:,:]) \n",
    "\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(ly, df[0], label='b_0')\n",
    "plt.plot(ly, df[1], label='b_1')\n",
    "plt.plot(ly, df[2], label='b_2')\n",
    "plt.plot(ly, df[3], label='b_3')\n",
    "plt.plot(ly, df[4], label='b_4')\n",
    "plt.plot(ly, df[5], label='b_5')\n",
    "plt.plot(ly, df[6], label='b_6')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Beta')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Implement your code using parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (Bonus 1 point) Find out which method is the lm() function in R is using? And which algorithm is being used? Or find out which method is the linear regression function (there are multiple, but only need to choose one) in numpy/scipy is using? And which algorithm is being used?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c178aea58de6e77b93b19ccdcc6dacff0444b89d2a7888d60013d84570d1a9a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
